namespace implies


/-
When working on logic in Lean, we can 
represent assumptions as axioms. For 
example, assume that an indentifier is 
bound to a value of a given type.
-/

axioms (P Q : Prop) 

/-
In this example, we use axiom to "assume"
that P and Q are names (identifiers) bound 
to two arbitrary propositions. 

A proposition, in our logic, is a type, 
the values of which constitute proofs of
that proposition. 

Propositions are special types, each being
of the special type, Prop. Prop is the type 
of all propositions. A proposition both is a 
type (of its proofs) and has a type (Prop).
-/

/-
Having assumed that P and Q are propositions,
next we assume that P is true. In a constructive
logic such as Lean, the way we represent that a
proposition is true is by assuming that we have
a proof of it. We thus represent the assumption
that there is a proof (value) of type P. 
-/

axiom p : P

/-
Next we want to assume that P → Q. In Enlish
we'd say that we want to assume P implies Q:
if P is true, then Q is true. P → Q is itself
a proposition, and to assume it's true, we'll
assume that we have a proof of it. 
-/

axiom pq : P → Q

/-
We now assumed both P → Q and P, represented
by the proof objects (values of these types)
p, and pq, respectively. These assumptions 
put us in a position to use the *elimination*
rule for → to deduce that Q is true (which is
to say, to construct a proof of Q).

In English, we could give a proof of Q like
this: 

Theorem: Q is true.

Proof: We have that P → Q is true and so is P. 
It follows from the elimination rule for → that
Q must be true.  

In constructive logic, we'd say this: Apply our 
(assumed) proof of P → Q to our (assumed) proof
of P to produce a proof of Q. This show that if
we're given any proof of P we can always create
a proof of Q by *applying* our proof of P → Q to
our proof of P.
-/

#check pq
#check p
#check (pq p) -- applying pq to p returns a proof of Q!

/-
Proof: By the elimination rule for → (with
pq applied to p).

Proof: By "modus ponens". QED 
-/

/-
Inference rule notation.

(P Q : Prop) (pq : P → Q) (p : P)
--------------------------------- → elim
              q : Q

-/

end implies

/-
FORALL
-/

namespace all

/-
To understand ∀ propositions, you really
have to understand *predicates*. A predicate
is a parameterized proposition. Think of it
as a proposition with blanks that you can 
fill in. Filling them in reduces a predicate
to a proposition *about* the specific values
that you used to fill in the blanks.

In constructive logic, (2) a predicate is just
a *function* that takes values for the blanks
and yields a proposition with the blanks filled
in with the given values. Predicates can take
any number of parameters.

A great example is *equality* it's a predicate
that takes two parameters (of the same type) 
and yeilds the proposition that those particular
values are equal: 0 = 0, 1 = 5, tt = ff, etc. 
Some of the resulting propositions are true (and
can be proved, e.g., 0 = 0), while some are not
true (e.g., 1=5), and have no proofs.

Another good example of a predicate is ev, our
"evenness predicate." It takes any arbitrary
natural number (say, n) as an argument and then
reduces to the proposition that that n is even,
in the sense that n % 2 = 0.
-/

def ev (n : ℕ) : Prop := n % 2 = 0

/-
The predicate ev applied to a natural number,
n, yields a result of type Prop (a proposition):
namely, the equality proposition n % 2 = 0. Here
are a few examples of propositions generated by
applying ev to various arguments (of type ℕ).
-/

-- Note that Lean reduces n%2 for us, given n
#reduce ev 0  -- yay 
#reduce ev 1  -- boo 
#reduce ev 2  -- yay 
#reduce ev 3  -- boo
#reduce ev 4  -- yay
#reduce ev 5  -- boo

/-
A predicate in effect defines a *set of values:
those values that satisfy the predicate: that 
produce a proposition that is true (for which
there are proofs.) Here it's clear that there
are proofs by reflexivity of equality for the
propositions, ev 0, ev 2, ev 4, but no proofs
for ev 1, ev 3, ev 5, etc. Predicate thus also
can be seen as defining *properties* of objects.
Here 0, 2, 4 have the property of being "ev",
while 1, 3, and 5 do not.
-/

/-
Now we can really get to a forall proposition.
Let's assert that every natural number is equal
to itself.
-/

theorem neqn : ∀ (n : ℕ), n = n := 
begin
  assume n,
  exact eq.refl n,
end

/-
The proof of this simple theorem is easy.
First we use the introduction rule for ∀:
we assume we're given an arbitrary natural
number, n. In that context we then need to
prove the rest, which we do by constructing
a proof that this arbitrary but specific n
is equal to itself.
-/

/-
What's remarkable is that we can *use* a
proof of a ∀ as a sort of function: in this
case, one that takes an arbitrary n as an
argument and that returns a proof of n = n.
-/

#reduce neqn 0
#reduce neqn 1
#reduce neqn 2


/-
Now let's be much more general about it. We
will make a few assumptions for purposes of 
an example.
-/
axioms 
  (T : Type)            -- T is any type
  (P : T → Prop)        -- P is any property (like ev)
  (t : T)               -- t is a specific value (like 1)
  (a : ∀ (x : T), P x)  -- a is a proof of this forall prop

/- 
We can now use the proof, a of the ∀ proposition,
to show that any specific value, such as t here, 
has the property P. We do this by applying the proof
a to t. This is the elimination rule for ∀ and is
called universal specialization or instantiation.
-/


example : P t := a t  
/-
Applying a to t yields a proof of the proposition P t.

In English, we've got a proof (a) of ∀ (x : T), P x.
We thus know that "every x has property P." To show
that a particular x, namely t, as property P, we use
the elimination rule for ∀ by applying a to t, which
then yields a proof that t, in particular, satisfies
the predicate P (has property P). QED.
-/ 

#check (a t)  -- syntax for application of a to t 

/-
Inference rule notation.

(T : Type) (P : T → Prop) (a : ∀ (x : T), P x) (t : T)
------------------------------------------------------ ∀ elim
                        pf: P t
-/

end all


/-
AND & → 
-/

/-
Inference rule / axioms for ∧ 

Introduction:

(P Q : Prop) (p : P) (q : Q)
---------------------------- ∧ intro
        ⟨p, q⟩ : P ∧ Q


(P Q : Prop) (pq : P ∧ Q)
------------------------- ∧ elim (left)
        p : P

(P Q : Prop) (pq : P ∧ Q)
------------------------- ∧ elim (right)
          q : Q
-/

axioms (P Q : Prop)     -- let's assume P, Q are propositions

-- Then so is (P ∧ Q) a proposition

#check P ∧ Q

-- Let's assume we have proofs of P and Q, respectively

axioms (p : P) (q : Q)

-- we can apply the introduction rule for ∧ 
def pq : P ∧ Q := and.intro p q 

-- Given a proof of P ∧ Q we can have proofs of P, Q, resp.
#check and.elim_left pq
#check and.elim_right pq

-- Here's a nice shorthand
#check pq.left
#check pq.right

/-
Theorem: Logical and is associative. What
this means is that if P ∧ (Q ∧ R) is true,
then so is (P ∧ Q) ∧ R.

First, think about it intuitively. If P is
true, we have a proof of it, call it p. If
(Q ∧ R) is true, we have a proof of it, call
it qr. From qr we can have a proof of Q and
a proof of R, call them q and r, respectively.

To show that (P ∧ Q) ∧ R is true, we need a
proof of P ∧ Q and a proof of R. We can apply
and.intro to p and q to get a proof, pq, of 
P ∧ Q. Finally, we can apply and.intro again
to pq and r to get the proof we sought. QED.
-/

/-
Exercise: formalize the proposition and
a proof of it.
-/

theorem and_associative : _ := _

-- Lean's proof of associativity
#check @and.assoc

/-
Note the use of a different connective,
bi-implication. We'll talk about how it
differs from simple implication shortly.
-/